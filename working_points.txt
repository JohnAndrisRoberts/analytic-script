Things to be Addressed:

(1) Weighting of incident radiation wavelength according to blackbody et al. spectra. COMPLETED

(2) Automated optimization - use of cluster computing to continually adjust layer parameters under some decently intelligent heuristic

	(2) a: Optimization is now contained in file autoOptimize.py, which ports information in and from of thinFilmClean.py. Currently optimization is not occurring, rather the code searches through space of interest, according to set material limitations (min_depth, max_depth, discrete_depth).

	(2) b: autoOptimize.py will either populate given space, and search through said space with an as of yet determined search protocol (BFS, A*, etc). Population of space may also occur with heuristic, when structure of space has been further studied (e.g. degeneracies given multiples of specific thicknesses, insensitivity to depth increase of terminal layer)

	(2) c: Implement rough heuristic built on fitness of cell as compared to outside thresholds set to become easier to maintain. Semi-greedy in the sense that the optimal solution is not picked, rather a family of promising solutions. Perhaps the space may be broken into sequentially finer gradations, choosing most promising subspaces (errors arise from proportionality in this case).

(3) Incorporating multiple angles of incidence (possibly weighted) and verifying proper results. Accounting for total internal reflection as well as extension of Snell's law to complex indices of refraction (there are methods available that are valid in the small-conductivity limit, but beyond that it seems as if people are having little luck). Either completely remove this, or categorize its caveats.

(4) Determine validity of the behavior currently shown in fabryPerot.py, and whether this suffices in application to Bouchon 2012. 

(5) Ought the method evaluateCells call on global variables? It makes interface more straightforward for the user, but perhaps obfuscates code. There is currently no problem in making such references explicitly. 

(6) Determine best implementation of barycenter/geometric-center determiners in choosing propagation direction. Not only must dim and step be chosen, but certain cells may be deactivated as well, if the path they are currently on is deemed non-useful (how should this apply to clusters of cells given multiple starting points?). Perhaps both the top performing cells as well as the barycenter may be used to pare down active cell count and dims to be traversed. Look for counter-examples where this produces not only sub-optimal behavior, but wrong behavior. 

(7) Keep in mind the structure of the space, either periodic or attenuating. This can drastically reduce the search space.

(8) Determine speed of array copying and method calling, given complexity of new system. If slow down is dramatic, see if architecture is incorrigible or simply badly planned. 

(9) Currently heuristic is working reasonably well given simple approach for selecting fit cells and fit direction for those cells to propagate. In addition to messing with these parameters (which would in theory require a different optimization algorithm which may have to be optimized itself, etc ad nauseum), major improvement involves the implementation of non-orthogonal propagation. That is, given various barycentric weighting as defined in the code, choose a variety of cells possible adjacent by only an edge or a corner. Done well, this will allow fluid and non-wasteful movement toward(s) optimum, and prevent 'gapping' due to clumsy flood. This appears to be the only idiosyncrasy at this point. Pinpoint causes (my thought is diffuse weighting from barycenter in symmetric situations) for this spottiness, and attempt to mitigate. There are a number of safeguards already in place for non-standard propagation environment (paltry active cells, bad heuristic, etc)

(10) Configure output and documentation to be relatively pleasant and user friendly, deciding which parameters are open to the public, and which ought not to be optimized. Call the entire thing from another interface, who knows. Compare data output of this particular simulation with gathered data from experiments, and streamline graphics for use in this comparison. 

(11) Determine if there is a way to search for local optima while excluding other local optima, or global optima. Threshold values are problematic, and breaking the space into regions may be the only way to accomplish a useful division of extrema. Current algorithm is non discerning (could however store a list of locally fittest cells, rather than globally) 

(12) See if use of activity parameter in autoOptimize's stack is cleaner, that is, is activeIndex superfluous or necessary to the architecture of this particular code.